"""
è®­ç»ƒæ—¥å¿—å¯è§†åŒ–å·¥å…·
ç”¨äºåˆ†æå’Œå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ä¸­çš„losså˜åŒ–
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import os
import argparse
from datetime import datetime
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class TrainingVisualizer:
    """è®­ç»ƒå¯è§†åŒ–å™¨"""
    
    def __init__(self, log_file):
        """åˆå§‹åŒ–å¯è§†åŒ–å™¨
        
        Args:
            log_file: CSVæ ¼å¼çš„è®­ç»ƒæ—¥å¿—æ–‡ä»¶è·¯å¾„
        """
        self.log_file = log_file
        self.data = None
        self.load_data()
    
    def load_data(self):
        """åŠ è½½è®­ç»ƒæ•°æ®"""
        try:
            self.data = pd.read_csv(self.log_file)
            print(f"âœ… æˆåŠŸåŠ è½½è®­ç»ƒæ—¥å¿—: {self.log_file}")
            print(f"ğŸ“Š æ•°æ®ç‚¹æ•°é‡: {len(self.data)}")
            print(f"ğŸ“ˆ è®­ç»ƒæ­¥æ•°èŒƒå›´: {self.data['step'].min()} - {self.data['step'].max()}")
            print(f"ğŸ“‰ LossèŒƒå›´: {self.data['loss'].min():.6f} - {self.data['loss'].max():.6f}")
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
            raise
    
    def plot_loss_curve(self, save_path=None, show_moving_avg=True, window_size=50):
        """ç»˜åˆ¶lossæ›²çº¿
        
        Args:
            save_path: ä¿å­˜è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™æ˜¾ç¤ºå›¾è¡¨
            show_moving_avg: æ˜¯å¦æ˜¾ç¤ºç§»åŠ¨å¹³å‡çº¿
            window_size: ç§»åŠ¨å¹³å‡çª—å£å¤§å°
        """
        plt.figure(figsize=(12, 8))
        
        # ç»˜åˆ¶åŸå§‹lossæ›²çº¿
        plt.plot(self.data['step'], self.data['loss'], 'b-', linewidth=1, alpha=0.6, label='Training Loss')
        
        # ç»˜åˆ¶ç§»åŠ¨å¹³å‡çº¿
        if show_moving_avg and len(self.data) >= window_size:
            moving_avg = self.data['loss'].rolling(window=window_size, center=True).mean()
            plt.plot(self.data['step'], moving_avg, 'r-', linewidth=2, label=f'Moving Average ({window_size} steps)')
        
        plt.xlabel('Training Steps')
        plt.ylabel('Loss')
        plt.title('Training Loss Over Time')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        min_loss = self.data['loss'].min()
        max_loss = self.data['loss'].max()
        final_loss = self.data['loss'].iloc[-1]
        plt.text(0.02, 0.98, f'Min Loss: {min_loss:.6f}\nFinal Loss: {final_loss:.6f}', 
                transform=plt.gca().transAxes, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š Lossæ›²çº¿å·²ä¿å­˜: {save_path}")
        else:
            plt.show()
        
        plt.close()
    
    def plot_learning_rate(self, save_path=None):
        """ç»˜åˆ¶å­¦ä¹ ç‡å˜åŒ–æ›²çº¿"""
        plt.figure(figsize=(12, 6))
        
        plt.plot(self.data['step'], self.data['learning_rate'], 'g-', linewidth=2, label='Learning Rate')
        plt.xlabel('Training Steps')
        plt.ylabel('Learning Rate')
        plt.title('Learning Rate Schedule')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š å­¦ä¹ ç‡æ›²çº¿å·²ä¿å­˜: {save_path}")
        else:
            plt.show()
        
        plt.close()
    
    def plot_comprehensive_analysis(self, save_path=None):
        """ç»˜åˆ¶ç»¼åˆåˆ†æå›¾è¡¨"""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. Lossæ›²çº¿
        axes[0, 0].plot(self.data['step'], self.data['loss'], 'b-', linewidth=1, alpha=0.7)
        if len(self.data) >= 50:
            moving_avg = self.data['loss'].rolling(window=50, center=True).mean()
            axes[0, 0].plot(self.data['step'], moving_avg, 'r-', linewidth=2)
        axes[0, 0].set_xlabel('Training Steps')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].set_title('Training Loss')
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. å­¦ä¹ ç‡æ›²çº¿
        axes[0, 1].plot(self.data['step'], self.data['learning_rate'], 'g-', linewidth=2)
        axes[0, 1].set_xlabel('Training Steps')
        axes[0, 1].set_ylabel('Learning Rate')
        axes[0, 1].set_title('Learning Rate Schedule')
        axes[0, 1].grid(True, alpha=0.3)
        axes[0, 1].ticklabel_format(style='scientific', axis='y', scilimits=(0,0))
        
        # 3. Lossåˆ†å¸ƒç›´æ–¹å›¾
        axes[1, 0].hist(self.data['loss'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        axes[1, 0].axvline(self.data['loss'].mean(), color='red', linestyle='--', label=f'Mean: {self.data["loss"].mean():.6f}')
        axes[1, 0].axvline(self.data['loss'].median(), color='green', linestyle='--', label=f'Median: {self.data["loss"].median():.6f}')
        axes[1, 0].set_xlabel('Loss Value')
        axes[1, 0].set_ylabel('Frequency')
        axes[1, 0].set_title('Loss Distribution')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. Lossæ”¹å–„è¶‹åŠ¿
        if len(self.data) >= 100:
            # è®¡ç®—æ¯100æ­¥çš„å¹³å‡loss
            step_groups = self.data.groupby(self.data['step'] // 100)['loss'].mean()
            axes[1, 1].plot(step_groups.index * 100, step_groups.values, 'o-', linewidth=2, markersize=4)
            axes[1, 1].set_xlabel('Training Steps (grouped by 100)')
            axes[1, 1].set_ylabel('Average Loss')
            axes[1, 1].set_title('Loss Improvement Trend')
            axes[1, 1].grid(True, alpha=0.3)
        else:
            axes[1, 1].text(0.5, 0.5, 'Not enough data\nfor trend analysis', 
                           ha='center', va='center', transform=axes[1, 1].transAxes)
            axes[1, 1].set_title('Loss Improvement Trend')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š ç»¼åˆåˆ†æå›¾è¡¨å·²ä¿å­˜: {save_path}")
        else:
            plt.show()
        
        plt.close()
    
    def generate_statistics_report(self, save_path=None):
        """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
        stats = {
            'æ€»è®­ç»ƒæ­¥æ•°': len(self.data),
            'åˆå§‹Loss': self.data['loss'].iloc[0],
            'æœ€ç»ˆLoss': self.data['loss'].iloc[-1],
            'æœ€ä½Loss': self.data['loss'].min(),
            'æœ€é«˜Loss': self.data['loss'].max(),
            'å¹³å‡Loss': self.data['loss'].mean(),
            'Lossæ ‡å‡†å·®': self.data['loss'].std(),
            'Lossæ”¹å–„': self.data['loss'].iloc[0] - self.data['loss'].iloc[-1],
            'æ”¹å–„ç™¾åˆ†æ¯”': ((self.data['loss'].iloc[0] - self.data['loss'].iloc[-1]) / self.data['loss'].iloc[0]) * 100
        }
        
        report = "=== è®­ç»ƒç»Ÿè®¡æŠ¥å‘Š ===\n"
        report += f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        report += f"æ•°æ®æ–‡ä»¶: {self.log_file}\n\n"
        
        for key, value in stats.items():
            if isinstance(value, float):
                report += f"{key}: {value:.6f}\n"
            else:
                report += f"{key}: {value}\n"
        
        # æ·»åŠ è®­ç»ƒæ—¶é—´åˆ†æ
        if 'elapsed_time' in self.data.columns:
            total_time = self.data['elapsed_time'].iloc[-1]
            report += f"\næ€»è®­ç»ƒæ—¶é—´: {total_time/3600:.2f} å°æ—¶\n"
            report += f"å¹³å‡æ¯æ­¥æ—¶é—´: {total_time/len(self.data):.2f} ç§’\n"
        
        print(report)
        
        if save_path:
            with open(save_path, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"ğŸ“‹ ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜: {save_path}")
        
        return stats

def find_latest_log_file(log_dir="./training_logs"):
    """æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒæ—¥å¿—æ–‡ä»¶"""
    if not os.path.exists(log_dir):
        raise FileNotFoundError(f"æ—¥å¿—ç›®å½•ä¸å­˜åœ¨: {log_dir}")
    
    csv_files = [f for f in os.listdir(log_dir) if f.startswith('training_log_') and f.endswith('.csv')]
    
    if not csv_files:
        raise FileNotFoundError(f"åœ¨ {log_dir} ä¸­æœªæ‰¾åˆ°è®­ç»ƒæ—¥å¿—æ–‡ä»¶")
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè¿”å›æœ€æ–°çš„
    csv_files.sort(key=lambda x: os.path.getmtime(os.path.join(log_dir, x)), reverse=True)
    latest_file = os.path.join(log_dir, csv_files[0])
    
    print(f"ğŸ” æ‰¾åˆ°æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶: {latest_file}")
    return latest_file

def main():
    parser = argparse.ArgumentParser(description='è®­ç»ƒæ—¥å¿—å¯è§†åŒ–å·¥å…·')
    parser.add_argument('--log_file', type=str, help='è®­ç»ƒæ—¥å¿—CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--log_dir', type=str, default='./training_logs', help='æ—¥å¿—ç›®å½•è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='./visualization_output', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--show', action='store_true', help='æ˜¾ç¤ºå›¾è¡¨è€Œä¸æ˜¯ä¿å­˜')
    
    args = parser.parse_args()
    
    # ç¡®å®šæ—¥å¿—æ–‡ä»¶
    if args.log_file:
        log_file = args.log_file
    else:
        log_file = find_latest_log_file(args.log_dir)
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = TrainingVisualizer(log_file)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    if not args.show:
        os.makedirs(args.output_dir, exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ç”Ÿæˆå„ç§å›¾è¡¨
        visualizer.plot_loss_curve(
            save_path=os.path.join(args.output_dir, f'loss_curve_{timestamp}.png')
        )
        visualizer.plot_learning_rate(
            save_path=os.path.join(args.output_dir, f'learning_rate_{timestamp}.png')
        )
        visualizer.plot_comprehensive_analysis(
            save_path=os.path.join(args.output_dir, f'comprehensive_analysis_{timestamp}.png')
        )
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        visualizer.generate_statistics_report(
            save_path=os.path.join(args.output_dir, f'statistics_report_{timestamp}.txt')
        )
        
        print(f"\nğŸ‰ æ‰€æœ‰å¯è§†åŒ–æ–‡ä»¶å·²ä¿å­˜åˆ°: {args.output_dir}")
    else:
        # æ˜¾ç¤ºå›¾è¡¨
        visualizer.plot_comprehensive_analysis()
        visualizer.generate_statistics_report()

if __name__ == "__main__":
    main()